{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"dates\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data and store in dataframe\n",
    "#csv = \"Resources/test10K.csv\"\n",
    "csv = \"Resources/GoBikeMerged2017_2018.csv\"\n",
    "df = spark.read.csv(csv, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------------+--------------+--------------------+---------------------+--------------------+--------------------+-----------------+-------------+----------------+----------------------+-----------------------+--------------------+--------------------+----------+------------------+-------------+------------------+-----------+-------+--------+-------------------+\n",
      "|_c0|bike_id|duration_sec|end_station_id|end_station_latitude|end_station_longitude|    end_station_name|            end_time|member_birth_year|member_gender|start_station_id|start_station_latitude|start_station_longitude|  start_station_name|          start_time| user_type|start_neighborhood|start_zipcode|  end_neighborhood|end_zipcode|temp(f)|pressure|weather_description|\n",
      "+---+-------+------------+--------------+--------------------+---------------------+--------------------+--------------------+-----------------+-------------+----------------+----------------------+-----------------------+--------------------+--------------------+----------+------------------+-------------+------------------+-----------+-------+--------+-------------------+\n",
      "|  0|    240|         424|          48.0|  37.782411189735896|  -122.39270595839115| 2nd St at S Park St|2017-06-28 09:54:...|           1985.0|       Female|            21.0|            37.7896254|            -122.400811|Montgomery St BAR...|2017-06-28 09:47:...|Subscriber|   South of Market|      94104.0|       China Basin|    94107.0|   62.0|  1021.0|         light_rain|\n",
      "|  1|    669|         366|          59.0|           37.774814|          -122.418954|S Van Ness Ave at...|2017-06-28 09:53:...|           1981.0|         Male|            58.0|             37.776619|            -122.417385|Market St at 10th St|2017-06-28 09:47:...|Subscriber|      Civic Center|      94103.0|   South of Market|    94103.0|   62.0|  1021.0|         light_rain|\n",
      "|  2|    117|         188|          48.0|  37.782411189735896|  -122.39270595839115| 2nd St at S Park St|2017-06-28 09:52:...|           1984.0|         Male|            25.0|     37.78752178045625|    -122.39740490913393| Howard St at 2nd St|2017-06-28 09:49:...|Subscriber|      The East Cut|      94105.0|       China Basin|    94107.0|   62.0|  1021.0|         light_rain|\n",
      "|  3|     77|        1201|           9.0|   37.79857210846257|  -122.40086898207666|Broadway at Batte...|2017-06-28 10:11:...|           1985.0|         Male|            81.0|              37.77588|             -122.39317|  Berry St at 4th St|2017-06-28 09:50:...|Subscriber|       China Basin|      94107.0|Financial District|    94111.0|   62.0|  1021.0|         light_rain|\n",
      "|  4|    316|         431|         321.0|   37.78014570345598|  -122.40307085237872|       5th at Folsom|2017-06-28 10:03:...|           1973.0|         Male|            66.0|     37.77874161153677|    -122.39274082710837|3rd St at Townsen...|2017-06-28 09:56:...|Subscriber|       China Basin|      94107.0|   South of Market|    94107.0|   62.0|  1021.0|         light_rain|\n",
      "|  5|    605|        1086|          90.0|           37.771058|          -122.402717|Townsend St at 7t...|2017-06-28 10:15:...|           1958.0|         Male|            15.0|             37.795392|            -122.394203|San Francisco Fer...|2017-06-28 09:56:...|Subscriber|       Embarcadero|      94105.0|       Mission Bay|    94103.0|   62.0|  1021.0|         light_rain|\n",
      "|  6|    272|         730|          44.0|          37.7810737|         -122.4117382|Civic Center/UN P...|2017-06-28 10:10:...|           1980.0|         Male|            23.0|     37.79146400000001|            -122.391034|The Embarcadero a...|2017-06-28 09:58:...|Subscriber|       South Beach|         null|        Mid-Market|    94103.0|   62.0|  1021.0|         light_rain|\n",
      "|  7|    400|         435|          45.0|           37.781752|          -122.405127| 5th St at Howard St|2017-06-28 10:08:...|           1991.0|         Male|            81.0|              37.77588|             -122.39317|  Berry St at 4th St|2017-06-28 10:00:...|Subscriber|       China Basin|      94107.0|   South of Market|    94103.0|   64.0|  1015.0|         light_rain|\n",
      "|  8|    212|         590|          22.0|           37.789756|          -122.394643|Howard St at Beal...|2017-06-28 10:10:...|           1983.0|         Male|            66.0|     37.77874161153677|    -122.39274082710837|3rd St at Townsen...|2017-06-28 10:00:...|Subscriber|       China Basin|      94107.0|   South of Market|    94105.0|   64.0|  1015.0|         light_rain|\n",
      "|  9|    915|         553|          50.0|           37.780526|  -122.39028799999998|2nd St at Townsen...|2017-06-28 10:18:...|           1973.0|         Male|            15.0|             37.795392|            -122.394203|San Francisco Fer...|2017-06-28 10:09:...|Subscriber|       Embarcadero|      94105.0|   South of Market|    94107.0|   64.0|  1015.0|         light_rain|\n",
      "| 10|    331|         640|          21.0|          37.7896254|          -122.400811|Montgomery St BAR...|2017-06-28 10:22:...|           1978.0|         Male|            66.0|     37.77874161153677|    -122.39274082710837|3rd St at Townsen...|2017-06-28 10:11:...|Subscriber|       China Basin|      94107.0|   South of Market|    94104.0|   64.0|  1015.0|         light_rain|\n",
      "| 11|    216|        5441|          42.0|            37.77865|           -122.41823|San Francisco Cit...|2017-06-28 11:42:...|           1974.0|         Male|            45.0|             37.781752|            -122.405127| 5th St at Howard St|2017-06-28 10:11:...|  Customer|   South of Market|      94103.0|      Civic Center|    94102.0|   64.0|  1015.0|         light_rain|\n",
      "| 12|    106|        2431|          42.0|            37.77865|           -122.41823|San Francisco Cit...|2017-06-28 10:53:...|           1979.0|       Female|            15.0|             37.795392|            -122.394203|San Francisco Fer...|2017-06-28 10:12:...|Subscriber|       Embarcadero|      94105.0|      Civic Center|    94102.0|   64.0|  1015.0|         light_rain|\n",
      "| 13|    200|         889|          23.0|   37.79146400000001|          -122.391034|The Embarcadero a...|2017-06-28 10:27:...|           1984.0|       Female|            15.0|             37.795392|            -122.394203|San Francisco Fer...|2017-06-28 10:12:...|Subscriber|       Embarcadero|      94105.0|       South Beach|       null|   64.0|  1015.0|         light_rain|\n",
      "| 14|    122|        1909|          42.0|            37.77865|           -122.41823|San Francisco Cit...|2017-06-28 10:45:...|           1984.0|         Male|            15.0|             37.795392|            -122.394203|San Francisco Fer...|2017-06-28 10:13:...|Subscriber|       Embarcadero|      94105.0|      Civic Center|    94102.0|   64.0|  1015.0|         light_rain|\n",
      "| 15|    248|        1908|          42.0|            37.77865|           -122.41823|San Francisco Cit...|2017-06-28 10:45:...|           1989.0|         Male|            15.0|             37.795392|            -122.394203|San Francisco Fer...|2017-06-28 10:13:...|Subscriber|       Embarcadero|      94105.0|      Civic Center|    94102.0|   64.0|  1015.0|         light_rain|\n",
      "| 16|    196|         410|          15.0|           37.795392|          -122.394203|San Francisco Fer...|2017-06-28 10:21:...|           1979.0|         Male|            11.0|              37.79728|            -122.398436|Davis St at Jacks...|2017-06-28 10:14:...|Subscriber|Financial District|      94111.0|       Embarcadero|    94105.0|   64.0|  1015.0|         light_rain|\n",
      "| 17|     20|         278|          13.0|           37.794231|          -122.402923|Commercial St at ...|2017-06-28 10:20:...|           1952.0|         Male|            15.0|             37.795392|            -122.394203|San Francisco Fer...|2017-06-28 10:16:...|Subscriber|       Embarcadero|      94105.0|Financial District|    94111.0|   64.0|  1015.0|         light_rain|\n",
      "| 18|     21|        2227|          42.0|            37.77865|           -122.41823|San Francisco Cit...| 2017-06-28 10:53:38|           1945.0|         Male|            15.0|             37.795392|            -122.394203|San Francisco Fer...|2017-06-28 10:16:...|Subscriber|       Embarcadero|      94105.0|      Civic Center|    94102.0|   64.0|  1015.0|         light_rain|\n",
      "| 19|    118|        2349|          42.0|            37.77865|           -122.41823|San Francisco Cit...|2017-06-28 10:55:...|             null|         null|            28.0|     37.78716801474664|    -122.38809792330359|The Embarcadero a...|2017-06-28 10:16:...|  Customer|       Embarcadero|      94105.0|      Civic Center|    94102.0|   64.0|  1015.0|         light_rain|\n",
      "+---+-------+------------+--------------+--------------------+---------------------+--------------------+--------------------+-----------------+-------------+----------------+----------------------+-----------------------+--------------------+--------------------+----------+------------------+-------------+------------------+-----------+-------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------+-------+-------------------+\n",
      "|_c0|          start_time|pressure|temp(f)|weather_description|\n",
      "+---+--------------------+--------+-------+-------------------+\n",
      "|  0|2017-06-28 09:47:...|  1021.0|   62.0|         light_rain|\n",
      "|  1|2017-06-28 09:47:...|  1021.0|   62.0|         light_rain|\n",
      "|  2|2017-06-28 09:49:...|  1021.0|   62.0|         light_rain|\n",
      "|  3|2017-06-28 09:50:...|  1021.0|   62.0|         light_rain|\n",
      "|  4|2017-06-28 09:56:...|  1021.0|   62.0|         light_rain|\n",
      "|  5|2017-06-28 09:56:...|  1021.0|   62.0|         light_rain|\n",
      "|  6|2017-06-28 09:58:...|  1021.0|   62.0|         light_rain|\n",
      "|  7|2017-06-28 10:00:...|  1015.0|   64.0|         light_rain|\n",
      "|  8|2017-06-28 10:00:...|  1015.0|   64.0|         light_rain|\n",
      "|  9|2017-06-28 10:09:...|  1015.0|   64.0|         light_rain|\n",
      "| 10|2017-06-28 10:11:...|  1015.0|   64.0|         light_rain|\n",
      "| 11|2017-06-28 10:11:...|  1015.0|   64.0|         light_rain|\n",
      "| 12|2017-06-28 10:12:...|  1015.0|   64.0|         light_rain|\n",
      "| 13|2017-06-28 10:12:...|  1015.0|   64.0|         light_rain|\n",
      "| 14|2017-06-28 10:13:...|  1015.0|   64.0|         light_rain|\n",
      "| 15|2017-06-28 10:13:...|  1015.0|   64.0|         light_rain|\n",
      "| 16|2017-06-28 10:14:...|  1015.0|   64.0|         light_rain|\n",
      "| 17|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|\n",
      "| 18|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|\n",
      "| 19|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|\n",
      "+---+--------------------+--------+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select(['_c0', 'start_time', 'pressure', 'temp(f)', 'weather_description'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find day of the week\n",
    "from pyspark.sql.functions import dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    " #df.select(dayofweek('datetime_PST').alias('day')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------+-------+-------------------+-----------+\n",
      "|_c0|          start_time|pressure|temp(f)|weather_description|day_of_week|\n",
      "+---+--------------------+--------+-------+-------------------+-----------+\n",
      "|  0|2017-06-28 09:47:...|  1021.0|   62.0|         light_rain|          4|\n",
      "|  1|2017-06-28 09:47:...|  1021.0|   62.0|         light_rain|          4|\n",
      "|  2|2017-06-28 09:49:...|  1021.0|   62.0|         light_rain|          4|\n",
      "|  3|2017-06-28 09:50:...|  1021.0|   62.0|         light_rain|          4|\n",
      "|  4|2017-06-28 09:56:...|  1021.0|   62.0|         light_rain|          4|\n",
      "|  5|2017-06-28 09:56:...|  1021.0|   62.0|         light_rain|          4|\n",
      "|  6|2017-06-28 09:58:...|  1021.0|   62.0|         light_rain|          4|\n",
      "|  7|2017-06-28 10:00:...|  1015.0|   64.0|         light_rain|          4|\n",
      "|  8|2017-06-28 10:00:...|  1015.0|   64.0|         light_rain|          4|\n",
      "|  9|2017-06-28 10:09:...|  1015.0|   64.0|         light_rain|          4|\n",
      "| 10|2017-06-28 10:11:...|  1015.0|   64.0|         light_rain|          4|\n",
      "| 11|2017-06-28 10:11:...|  1015.0|   64.0|         light_rain|          4|\n",
      "| 12|2017-06-28 10:12:...|  1015.0|   64.0|         light_rain|          4|\n",
      "| 13|2017-06-28 10:12:...|  1015.0|   64.0|         light_rain|          4|\n",
      "| 14|2017-06-28 10:13:...|  1015.0|   64.0|         light_rain|          4|\n",
      "| 15|2017-06-28 10:13:...|  1015.0|   64.0|         light_rain|          4|\n",
      "| 16|2017-06-28 10:14:...|  1015.0|   64.0|         light_rain|          4|\n",
      "| 17|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|          4|\n",
      "| 18|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|          4|\n",
      "| 19|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|          4|\n",
      "+---+--------------------+--------+-------+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the day of the week as a new column\n",
    "df = df.withColumn(\"day_of_week\", dayofweek('start_time'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------+-------+-------------------+-----------+----+----+-----+------------+\n",
      "|_c0|          start_time|pressure|temp(f)|weather_description|day_of_week|hour|year|month|day_of_month|\n",
      "+---+--------------------+--------+-------+-------------------+-----------+----+----+-----+------------+\n",
      "|  0|2017-06-28 09:47:...|  1021.0|   62.0|         light_rain|          4|   9|2017|    6|          28|\n",
      "|  1|2017-06-28 09:47:...|  1021.0|   62.0|         light_rain|          4|   9|2017|    6|          28|\n",
      "|  2|2017-06-28 09:49:...|  1021.0|   62.0|         light_rain|          4|   9|2017|    6|          28|\n",
      "|  3|2017-06-28 09:50:...|  1021.0|   62.0|         light_rain|          4|   9|2017|    6|          28|\n",
      "|  4|2017-06-28 09:56:...|  1021.0|   62.0|         light_rain|          4|   9|2017|    6|          28|\n",
      "|  5|2017-06-28 09:56:...|  1021.0|   62.0|         light_rain|          4|   9|2017|    6|          28|\n",
      "|  6|2017-06-28 09:58:...|  1021.0|   62.0|         light_rain|          4|   9|2017|    6|          28|\n",
      "|  7|2017-06-28 10:00:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "|  8|2017-06-28 10:00:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "|  9|2017-06-28 10:09:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 10|2017-06-28 10:11:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 11|2017-06-28 10:11:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 12|2017-06-28 10:12:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 13|2017-06-28 10:12:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 14|2017-06-28 10:13:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 15|2017-06-28 10:13:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 16|2017-06-28 10:14:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 17|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 18|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 19|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "+---+--------------------+--------+-------+-------------------+-----------+----+----+-----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the day of the week as a new column\n",
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "df = df.withColumn(\"year\", year('start_time'))\n",
    "df = df.withColumn(\"month\", month('start_time'))\n",
    "df = df.withColumn(\"day_of_month\", dayofmonth('start_time'))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out weekend days (day 1 is Sunday, day 7 is Saturday)\n",
    "df_weekdays = df.filter( (df[\"day_of_week\"] > 1) | (df['day_of_week'] < 7) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------+-------+-------------------+-----------+----+----+-----+------------+\n",
      "|_c0|          start_time|pressure|temp(f)|weather_description|day_of_week|hour|year|month|day_of_month|\n",
      "+---+--------------------+--------+-------+-------------------+-----------+----+----+-----+------------+\n",
      "|  0|2017-06-28 09:47:...|  1021.0|   62.0|         light_rain|          4|   9|2017|    6|          28|\n",
      "|  1|2017-06-28 09:47:...|  1021.0|   62.0|         light_rain|          4|   9|2017|    6|          28|\n",
      "|  2|2017-06-28 09:49:...|  1021.0|   62.0|         light_rain|          4|   9|2017|    6|          28|\n",
      "|  3|2017-06-28 09:50:...|  1021.0|   62.0|         light_rain|          4|   9|2017|    6|          28|\n",
      "|  4|2017-06-28 09:56:...|  1021.0|   62.0|         light_rain|          4|   9|2017|    6|          28|\n",
      "|  5|2017-06-28 09:56:...|  1021.0|   62.0|         light_rain|          4|   9|2017|    6|          28|\n",
      "|  6|2017-06-28 09:58:...|  1021.0|   62.0|         light_rain|          4|   9|2017|    6|          28|\n",
      "|  7|2017-06-28 10:00:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "|  8|2017-06-28 10:00:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "|  9|2017-06-28 10:09:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 10|2017-06-28 10:11:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 11|2017-06-28 10:11:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 12|2017-06-28 10:12:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 13|2017-06-28 10:12:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 14|2017-06-28 10:13:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 15|2017-06-28 10:13:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 16|2017-06-28 10:14:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 17|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 18|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "| 19|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|          4|  10|2017|    6|          28|\n",
      "+---+--------------------+--------+-------+-------------------+-----------+----+----+-----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weekdays.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do\n",
    "#Filter out holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------+-------+-------------------+-----------+----+\n",
      "|_c0|          start_time|pressure|temp(f)|weather_description|day_of_week|hour|\n",
      "+---+--------------------+--------+-------+-------------------+-----------+----+\n",
      "|  0|2017-06-28 09:47:...|  1021.0|   62.0|         light_rain|          4|   9|\n",
      "|  1|2017-06-28 09:47:...|  1021.0|   62.0|         light_rain|          4|   9|\n",
      "|  2|2017-06-28 09:49:...|  1021.0|   62.0|         light_rain|          4|   9|\n",
      "|  3|2017-06-28 09:50:...|  1021.0|   62.0|         light_rain|          4|   9|\n",
      "|  4|2017-06-28 09:56:...|  1021.0|   62.0|         light_rain|          4|   9|\n",
      "|  5|2017-06-28 09:56:...|  1021.0|   62.0|         light_rain|          4|   9|\n",
      "|  6|2017-06-28 09:58:...|  1021.0|   62.0|         light_rain|          4|   9|\n",
      "|  7|2017-06-28 10:00:...|  1015.0|   64.0|         light_rain|          4|  10|\n",
      "|  8|2017-06-28 10:00:...|  1015.0|   64.0|         light_rain|          4|  10|\n",
      "|  9|2017-06-28 10:09:...|  1015.0|   64.0|         light_rain|          4|  10|\n",
      "| 10|2017-06-28 10:11:...|  1015.0|   64.0|         light_rain|          4|  10|\n",
      "| 11|2017-06-28 10:11:...|  1015.0|   64.0|         light_rain|          4|  10|\n",
      "| 12|2017-06-28 10:12:...|  1015.0|   64.0|         light_rain|          4|  10|\n",
      "| 13|2017-06-28 10:12:...|  1015.0|   64.0|         light_rain|          4|  10|\n",
      "| 14|2017-06-28 10:13:...|  1015.0|   64.0|         light_rain|          4|  10|\n",
      "| 15|2017-06-28 10:13:...|  1015.0|   64.0|         light_rain|          4|  10|\n",
      "| 16|2017-06-28 10:14:...|  1015.0|   64.0|         light_rain|          4|  10|\n",
      "| 17|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|          4|  10|\n",
      "| 18|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|          4|  10|\n",
      "| 19|2017-06-28 10:16:...|  1015.0|   64.0|         light_rain|          4|  10|\n",
      "+---+--------------------+--------+-------+-------------------+-----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the hour of the day as a new column\n",
    "from pyspark.sql.functions import hour\n",
    "df = df.withColumn(\"hour\", hour('start_time'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------+----+-----------+--------+-------+-------------------+-----+\n",
      "|year|month|day_of_month|hour|day_of_week|pressure|temp(f)|weather_description|count|\n",
      "+----+-----+------------+----+-----------+--------+-------+-------------------+-----+\n",
      "|2017|    7|           1|   2|          7|  1017.0|   61.0|         light_rain|    3|\n",
      "|2017|    7|           6|   9|          5|  1019.0|   66.0|       thunderstorm|  113|\n",
      "|2017|    7|          29|   2|          7|  1014.0|   59.0|         light_rain|    3|\n",
      "|2017|    7|          31|   2|          2|  1018.0|   60.0|         light_rain|    1|\n",
      "|2017|    8|           9|  13|          4|  1016.0|   68.0|             cloudy|   96|\n",
      "|2017|    8|          20|  18|          1|  1011.0|   76.0|        clear_skies|   95|\n",
      "|2017|    8|          31|  15|          5|  1009.0|   89.0|              foggy|  137|\n",
      "|2017|    9|           6|   5|          4|  1014.0|   66.0|              foggy|   17|\n",
      "|2017|    9|           8|  15|          6|  1012.0|   77.0|        clear_skies|  184|\n",
      "|2017|    9|          17|  13|          1|  1016.0|   72.0|             cloudy|  215|\n",
      "|2017|    9|          21|  11|          5|  1013.0|   65.0|             cloudy|  160|\n",
      "|2017|    9|          27|  14|          4|  1012.0|   86.0|        clear_skies|  109|\n",
      "|2017|   10|           5|  16|          5|  1015.0|   81.0|        clear_skies|  268|\n",
      "|2017|   10|           7|  21|          7|  1009.0|   64.0|        clear_skies|   52|\n",
      "|2017|   10|          16|  21|          2|  1017.0|   67.0|              foggy|  172|\n",
      "|2017|   10|          28|  21|          7|  1013.0|   59.0|         light_rain|   36|\n",
      "|2017|   11|           4|  22|          7|  1018.0|   53.0|             cloudy|   34|\n",
      "|2017|   11|           8|   5|          4|  1016.0|   50.0|             cloudy|   16|\n",
      "|2017|   11|           8|  19|          4|  1012.0|   64.0|         light_rain|  278|\n",
      "|2017|   11|          10|  15|          6|  1017.0|   65.0|         heavy_rain|  171|\n",
      "+----+-----+------------+----+-----------+--------+-------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_df = df.groupBy(['year', 'month', 'day_of_month', 'hour', 'day_of_week', 'pressure', 'temp(f)', 'weather_description']).count()\n",
    "#grouped_df = df.groupBy(['hour']).count()\n",
    "grouped_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a simple data set with day of the week, hour and bikeride count\n",
    "#simple_df = df.groupBy(['hour', 'day_of_week']).count()\n",
    "#simple_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pandas_df = grouped_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing rows with no hours\n",
    "pandas_df = pandas_df[pandas_df.hour.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9606, 9)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count number of rows\n",
    "pandas_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9606, 2) (9606,)\n"
     ]
    }
   ],
   "source": [
    "#X = pandas_df.drop(\"count\", axis=1)\n",
    "X = pandas_df.drop(columns=['year', 'month', 'day_of_month', 'pressure', 'temp(f)', 'weather_description', 'count'])\n",
    "y = pandas_df[\"count\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
       "         12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,\n",
       "         23,   24,   25,   26,   27,   28,   29,   30,   31,   32,   33,\n",
       "         34,   35,   36,   37,   38,   39,   40,   41,   42,   43,   44,\n",
       "         45,   46,   47,   48,   49,   50,   51,   52,   53,   54,   55,\n",
       "         56,   57,   58,   59,   60,   61,   62,   63,   64,   65,   66,\n",
       "         67,   68,   69,   70,   71,   72,   73,   74,   75,   76,   77,\n",
       "         78,   79,   80,   81,   82,   83,   84,   85,   86,   87,   88,\n",
       "         89,   90,   91,   92,   93,   94,   95,   96,   97,   98,   99,\n",
       "        100,  101,  102,  103,  104,  105,  106,  107,  108,  109,  110,\n",
       "        111,  112,  113,  114,  115,  116,  117,  118,  119,  120,  121,\n",
       "        122,  123,  124,  125,  126,  127,  128,  129,  130,  131,  132,\n",
       "        133,  134,  135,  136,  137,  138,  139,  140,  141,  142,  143,\n",
       "        144,  145,  146,  147,  148,  149,  150,  151,  152,  153,  154,\n",
       "        155,  156,  157,  158,  159,  160,  161,  162,  163,  164,  165,\n",
       "        166,  167,  168,  169,  170,  171,  172,  173,  174,  175,  176,\n",
       "        177,  178,  179,  180,  181,  182,  183,  184,  185,  186,  187,\n",
       "        188,  189,  190,  191,  192,  193,  194,  195,  196,  197,  198,\n",
       "        199,  200,  201,  202,  203,  204,  205,  206,  207,  208,  209,\n",
       "        210,  211,  212,  213,  214,  215,  216,  217,  218,  219,  220,\n",
       "        221,  222,  223,  224,  225,  226,  227,  228,  229,  230,  231,\n",
       "        232,  233,  234,  235,  236,  237,  238,  239,  240,  241,  242,\n",
       "        243,  244,  245,  246,  247,  248,  249,  250,  251,  252,  253,\n",
       "        254,  255,  256,  257,  258,  259,  260,  261,  262,  263,  264,\n",
       "        265,  266,  267,  268,  269,  270,  271,  272,  273,  274,  275,\n",
       "        276,  277,  278,  279,  280,  281,  282,  283,  284,  285,  286,\n",
       "        287,  288,  289,  290,  291,  292,  293,  294,  295,  296,  297,\n",
       "        298,  299,  300,  301,  302,  303,  304,  305,  306,  307,  308,\n",
       "        309,  310,  311,  312,  313,  314,  315,  316,  317,  318,  319,\n",
       "        320,  321,  322,  323,  324,  325,  326,  327,  328,  329,  330,\n",
       "        332,  333,  334,  335,  336,  337,  338,  339,  340,  341,  342,\n",
       "        343,  344,  345,  346,  347,  348,  349,  350,  351,  352,  353,\n",
       "        354,  355,  356,  357,  358,  359,  360,  361,  362,  363,  364,\n",
       "        365,  366,  367,  368,  369,  370,  371,  372,  373,  374,  375,\n",
       "        376,  377,  378,  380,  381,  382,  383,  384,  385,  386,  387,\n",
       "        388,  389,  390,  391,  392,  393,  394,  395,  396,  397,  398,\n",
       "        399,  400,  401,  402,  403,  404,  405,  406,  407,  408,  409,\n",
       "        410,  411,  412,  413,  414,  415,  416,  417,  418,  419,  420,\n",
       "        421,  422,  423,  424,  425,  426,  427,  428,  429,  430,  431,\n",
       "        432,  433,  434,  435,  436,  437,  439,  440,  441,  442,  443,\n",
       "        444,  445,  446,  447,  448,  449,  450,  451,  452,  454,  456,\n",
       "        457,  458,  459,  460,  461,  462,  463,  464,  465,  466,  467,\n",
       "        468,  469,  472,  474,  475,  476,  477,  478,  479,  480,  481,\n",
       "        482,  483,  484,  485,  486,  487,  488,  489,  491,  492,  493,\n",
       "        494,  495,  496,  497,  498,  499,  500,  501,  503,  504,  505,\n",
       "        506,  507,  508,  509,  510,  511,  512,  513,  514,  515,  517,\n",
       "        518,  519,  520,  521,  522,  523,  524,  525,  526,  527,  529,\n",
       "        530,  531,  532,  533,  534,  536,  537,  538,  539,  540,  541,\n",
       "        542,  543,  545,  546,  547,  549,  550,  551,  552,  553,  554,\n",
       "        555,  556,  557,  558,  559,  560,  561,  562,  563,  564,  565,\n",
       "        566,  567,  569,  571,  572,  574,  576,  579,  580,  581,  582,\n",
       "        583,  585,  586,  587,  588,  591,  594,  596,  597,  598,  600,\n",
       "        601,  602,  603,  604,  612,  613,  619,  621,  623,  624,  628,\n",
       "        630,  633,  634,  638,  640,  642,  645,  649,  650,  651,  655,\n",
       "        660,  664,  666,  672,  673,  674,  675,  677,  680,  684,  686,\n",
       "        687,  689,  690,  691,  694,  697,  698,  699,  704,  707,  710,\n",
       "        713,  718,  719,  720,  721,  724,  727,  729,  730,  733,  734,\n",
       "        740,  742,  743,  744,  746,  749,  758,  761,  762,  764,  767,\n",
       "        768,  769,  771,  773,  774,  775,  776,  778,  780,  782,  783,\n",
       "        784,  786,  788,  796,  806,  807,  811,  812,  815,  816,  818,\n",
       "        820,  830,  832,  834,  836,  844,  852,  864,  884,  894,  916,\n",
       "        946,  968, 1008, 1203, 1263, 1743])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-0e76413884c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[0;32m----> 6\u001b[0;31m     X, y, random_state=1, stratify=y)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2054\u001b[0m                      random_state=random_state)\n\u001b[1;32m   2055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n",
      "\u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \"\"\"\n\u001b[1;32m   1203\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1544\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1546\u001b[0;31m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[1;32m   1547\u001b[0m                              \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m                              \u001b[0;34m\" number of groups for any class cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1, stratify=y)\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
